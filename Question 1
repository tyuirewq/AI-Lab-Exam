import numpy as np

class Engine:
    def __init__(self, reward, correctProbability):
        self.REWARD = reward
        self.PROBABILITY = correctProbability
        self.next = None

class Agent:
    def __init__(self):
        self.N = 10
        self.THETA = 0.0001
        self.DISCOUNT_FACTOR = 0.9
        self.action = ["PLAY", "QUIT"]
        
        REWARDS = [100, 500, 1000, 5000, 10000, 50000, 100000, 500000, 1000000, 5000000]
        pb = [0.99, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]
        
        Intial = Engine(-1,0)
        TEMP = Intial
        
        for i in range(self.N):  
            TEMP.next = Engine(REWARDS[i],pb[i])
            TEMP = TEMP.next
        
        self.START_STATE = Intial.next        

class Solution:
    def __init__(self):
        self.agent = Agent()
        self.vf = {s: 0 for s in range(self.agent.N)}
        self.ITERATIONS = 0
        self.reach = {s: 0 for s in range(self.agent.N)}
        self.TERMINATOR = False
    
    def helper(self, state, iteration):
        if(state == None): return 0
        self.reach[iteration] += 1
    
        OLD_VALUE = self.vf[iteration]
        reward = 0
        if iteration == 0:
            QUIT_REWARD = 0
        else:
            QUIT_REWARD = self.vf[iteration-1]
        
        ans = np.random.rand()
        
        if ans <= state.PROBABILITY:
            reward = state.PROBABILITY * (state.REWARD + (self.agent.DISCOUNT_FACTOR * self.helper(state.next, iteration+1)))
            self.vf[iteration] = (self.vf[iteration] * self.reach[iteration] + reward)/(self.reach[iteration]+1)
            
            if(abs(self.vf[iteration] - OLD_VALUE) < self.agent.THETA):
                self.TERMINATOR = True

        return max(QUIT_REWARD, reward)
    
    def solver(self):
        while self.TERMINATOR == False:
            self.ITERATIONS += 1
            HEAD = self.agent.START_STATE
            self.helper(HEAD, 0)
        
        print("Total Iterations: ", self.ITERATIONS)
        print("VALUE FUNCTION:")
        print(self.vf)
        
        EXPECTATION = 0
        for i in range(self.agent.N):
            EXPECTATION = EXPECTATION + ((self.reach[i]/100) * self.vf[i])
        
        print("EXPECTED REWARD: ", EXPECTATION)

Solution().solver()
